
# ğŸ§ª Differential Privacy Demo â€“ Walkthrough

This walkthrough explains how the DP demo is structured and what each component does.

---

## ğŸ“ Files Overview

You have two main model training scripts:

1. **`baseline_model.py`** â€” Regular model with no privacy
2. **`dp_model.py`** â€” Differentially private model using TensorFlow Privacy

And a visual React demo file:

- **`dp_demo.jsx`** â€” Interactive privacy vs accuracy visualizer

---

## âœ… Baseline Model (`baseline_model.py`)

This is a standard training script for the MNIST dataset.

### ğŸ” What It Does:
- Loads and normalizes the MNIST dataset
- Flattens the 28x28 images into 784-pixel vectors
- Defines a basic neural network:
  ```python
  tf.keras.Sequential([
      tf.keras.layers.InputLayer(input_shape=(784,)),
      tf.keras.layers.Dense(128, activation='relu'),
      tf.keras.layers.Dense(10)
  ])
  ```
- Compiles the model with:
  - `SparseCategoricalCrossentropy` loss
  - `Adam` optimizer
- Trains using `.fit()` and evaluates accuracy on the test set

### âœ… Result:
- **High accuracy (~97.86%)**
- **No privacy protection**
- Represents a best-case performance baseline

---

## ğŸ›¡ï¸ DP Model (`dp_model.py`)

This version uses Differential Privacy to protect individual training examples.

### ğŸ” What It Changes:
- Uses `DPKerasSGDOptimizer`:
  ```python
  DPKerasSGDOptimizer(
      l2_norm_clip=1.0,
      noise_multiplier=1.1,
      num_microbatches=256,
      learning_rate=0.25
  )
  ```
- Adds noise to gradients and clips them to limit individual impact
- Requires loss reduction set to `NONE` to compute per-example gradients:
  ```python
  loss = tf.keras.losses.SparseCategoricalCrossentropy(
      from_logits=True,
      reduction=tf.keras.losses.Reduction.NONE
  )
  ```
- Trains as usual with `.fit()`
- Uses `compute_dp_sgd_privacy()` to compute **Îµ (epsilon)**

### ğŸ“‰ Result:
- **Accuracy ~91.91%**
- **Privacy Guarantee: Îµ = 1.28**
- Shows privacy-accuracy tradeoff

---

## ğŸ›ï¸ React Visual Demo (`dp_demo.jsx`)

This is the interactive front-end for demo presentations.

### âœ¨ Features:
- Slider to adjust Îµ (epsilon) in real time
- Live comparison of:
  - ğŸŸ¢ **Baseline Accuracy**
  - ğŸ›¡ï¸ **DP Accuracy** (changes with Îµ)
- Popover dialog explaining **what Îµ is**
- Labels for privacy strength (e.g., â€œVery Strong Privacyâ€)

### ğŸ“Š Purpose:
- Make the accuracy vs privacy tradeoff visual
- Explain Îµ to stakeholders in plain English
- Show that Differential Privacy is measurable and tunable

---

## ğŸ§  What the Demo Teaches

- **Privacyâ€“Accuracy Tradeoff** is real and tunable
- **Îµ (Epsilon)** is a measurable privacy budget
- **Differential Privacy is practical** â€” not just theory
- **Baseline vs DP** comparison is key for understanding model hardening

---

## Want More?

Ask for:
- A slide-ready summary
- Exportable PDF or printable one-pager
- GitHub README integration
